{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ab83585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q langchain_community tiktoken langchain-openai langchainhub chromadb langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4029e7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from access import Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c4416ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
    "os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'\n",
    "os.environ['LANGCHAIN_API_KEY'] = Access.LANGCHAIN_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a491fd",
   "metadata": {},
   "source": [
    "## Part 1: Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3a328c7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Reward hacking is when an agent interferes with the reward function to achieve its own goals, rather than following the intended objective. This can be done by manipulating the reward function directly or altering environmental information used for it. It's a broader concept that includes both environment/goal misspecification and reward tampering.\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import bs4\n",
    "from langchain_classic import hub\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_ollama import ChatOllama, OllamaEmbeddings\n",
    "\n",
    "# === Indexing ===\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2024-11-28-reward-hacking/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "\n",
    "docs = loader.load()\n",
    "\n",
    "# Split\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "\n",
    "# Embed\n",
    "vectorstore = Chroma.from_documents(documents=splits,\n",
    "                                    embedding=OllamaEmbeddings(model=\"mxbai-embed-large\"))\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# === Retrieval and Generation ===\n",
    "\n",
    "# Prompt\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "# LLM\n",
    "llm = ChatOllama(\n",
    "    model=\"llama3.1\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "# Post-processing\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# Chain\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()} | prompt | llm | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Question\n",
    "rag_chain.invoke(\"What is reward hacking if you had to explain it in a very simple way.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e64256",
   "metadata": {},
   "source": [
    "## Part 2: Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "79aefa41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documents\n",
    "question = \"What kinds of pets do I like?\"\n",
    "document = \"My favorite pet is a cat.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fd70d76e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "num_tokens_from_string(question, \"cl100k_base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c57b4c0",
   "metadata": {},
   "source": [
    "# tiktoken is a fast open-source tokenizer by OpenAI\n",
    "# It convers a text string such as \"tiktoken is great!\" using encoding method such as \"cl100k_base\" to split the text string into a list of tokens [\"t\", \"ik\", \"token\", \" is\", \" great\", \"!\"].\n",
    "\n",
    "# This is useful because GPT models see text in the form of tokens. Knowing the size of token is helpful to decide whether the string is too long for a text model to process and how much an OpenAI API call costs (usage price per token)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6c944c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaEmbeddings\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
