{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fdfb478",
   "metadata": {},
   "source": [
    "# RAG from Scratch: Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "229abeba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q -U langchain langchain_core"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0d6825",
   "metadata": {},
   "source": [
    "## Chunking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0b1efc",
   "metadata": {},
   "source": [
    "Chunking is important to extract and group relevant informations in the same chunk so that when the retriever retrieve the data, the correct chunk will be pulled and it will bring the most relevant information.\n",
    "\n",
    "The chunk can be processed and embedded, and later the AI system can retrieve the embeddings to obtain the most relevant sources.\n",
    "\n",
    "Why Chunking is important?\n",
    "- LLM and RAG pipelines has limitation in the context windows and computational constraints, so we have to fit as much information as we can inside the same chunk.\n",
    "- Without proper chunking, we lose important contextual relationship and struggle to identify relevant information during retrieval.\n",
    "- Effective chunking will enhance the precision due to the semantically coherent segments that align with query patterns and user intent.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5687f7c2",
   "metadata": {},
   "source": [
    "\n",
    "## Common Chunking Strategies (w/ examples):\n",
    "\n",
    "> Example text:\n",
    ">\n",
    ">\"The Journey of a River from its source in the mountains through forests, cities, and finally into the sea is a fascinating story of nature's cycle and human interaction with the environment.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1a5acae",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"The Journey of a River from its source in the mountains through forests, cities, and finally into the sea is a fascinating story of nature's cycle and human interaction with the environment.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fc4c8b",
   "metadata": {},
   "source": [
    "### 1. Fixed Size Chunking\n",
    "This is the simplest but computationally effective method, it splits the text into chunk based on characters, words, or tokens without considering the meaning or the structure.\n",
    "\n",
    "Advantages:\n",
    "+ Fast\n",
    "+ Predictable\n",
    "+ Easy to implement\n",
    "\n",
    "Drawbacks:\n",
    "- Ignores semantic structure (reduces retrieval accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "596906a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Manual Character Text Splitting ####\n",
      "[Document(metadata={'source': 'local'}, page_content='The Journey of a River from its sou'), Document(metadata={'source': 'local'}, page_content='rce in the mountains through forest'), Document(metadata={'source': 'local'}, page_content='s, cities, and finally into the sea'), Document(metadata={'source': 'local'}, page_content=\" is a fascinating story of nature's\"), Document(metadata={'source': 'local'}, page_content=' cycle and human interaction with t'), Document(metadata={'source': 'local'}, page_content='he environment.')]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "print(\"#### Manual Character Text Splitting ####\")\n",
    "\n",
    "# manual character chunking\n",
    "chunks = []\n",
    "chunk_size = 35\n",
    "\n",
    "for i in range(0, len(text), chunk_size):\n",
    "    chunk = text[i:i + chunk_size]\n",
    "    chunks.append(chunk)\n",
    "    \n",
    "documents = [Document(page_content=chunk, metadata={\"source\": \"local\"}) for chunk in chunks]\n",
    "print(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef620aa",
   "metadata": {},
   "source": [
    "Result:\n",
    "\n",
    "[ <br/>\n",
    "    'The Journey of a River from its sou', <br/>\n",
    "    'rce in the mountains through forest', <br/>\n",
    "    's, cities, and finally into the sea', <br/>\n",
    "    \" is a fascinating story of nature's\", <br/>\n",
    "    ' cycle and human interaction with t', <br/>\n",
    "    'he environment.' <br/>\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c51b1f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Automatic Character Text Splitting ####\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/reiner/Documents/GitHub/llm_rag_from_scratch/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={}, page_content='The Journey of a River from its sou'), Document(metadata={}, page_content='s source in the mountains through f'), Document(metadata={}, page_content='ugh forests, cities, and finally in'), Document(metadata={}, page_content='ly into the sea is a fascinating st'), Document(metadata={}, page_content=\"ng story of nature's cycle and huma\"), Document(metadata={}, page_content=' human interaction with the environ'), Document(metadata={}, page_content='vironment.')]\n"
     ]
    }
   ],
   "source": [
    "# Automatic Text Splitting\n",
    "\n",
    "print(\"#### Automatic Character Text Splitting ####\")\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "text_splitter = CharacterTextSplitter(chunk_size = 35, chunk_overlap=5, separator='', strip_whitespace=False)\n",
    "documents = text_splitter.create_documents([text])\n",
    "print(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdc41fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Journey of a River from its sou | size = 35\n",
      "s source in the mountains through f | size = 35\n",
      "ugh forests, cities, and finally in | size = 35\n",
      "ly into the sea is a fascinating st | size = 35\n",
      "ng story of nature's cycle and huma | size = 35\n",
      " human interaction with the environ | size = 35\n",
      "vironment. | size = 10\n"
     ]
    }
   ],
   "source": [
    "# print(len(result))\n",
    "for i in documents:\n",
    "    print(f'{i.page_content} | size = {len(i.page_content)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86bd91f",
   "metadata": {},
   "source": [
    "The result is supposed to be exactly the same, but because we add overlap value of 5 characters, each Documents entry will overlap giving us even more result which could carry a more complete information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a725e2bb",
   "metadata": {},
   "source": [
    "### 2. Recursive Character Text Splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c7ac62",
   "metadata": {},
   "source": [
    "This is a more dynamic approach to the original chunking method and it focuses more on the structure. It will split the text based on the separator priority. By default, the separator priority is [\"\\n\\n\", \"\\n\", \" \", \"\"]. What is will do is split it one by one and check whether the size is still larger than the required chunk value, if true, it will chunk it into smaller sections with the next separator."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56601b2",
   "metadata": {},
   "source": [
    "sample text from `content.txt`:\n",
    "\n",
    "Reiner is a student from National University of Singapore (NUS). He is taking his Master of Computing with Artificial Intelligence Specialization there.\\n\\nHe is 25 years old currently and have been working on some personal projects to extend his expertise and knowledge.\\n\\nHis personal hobby is playing basketball and playing games."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59be5707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Recursive Character Text Splitting ####\n",
      "[Document(metadata={}, page_content='Reiner is a student'), Document(metadata={}, page_content='from National'), Document(metadata={}, page_content='University of'), Document(metadata={}, page_content='Singapore (NUS). He'), Document(metadata={}, page_content='is taking his'), Document(metadata={}, page_content='Master of Computing'), Document(metadata={}, page_content='with Artificial'), Document(metadata={}, page_content='Intelligence'), Document(metadata={}, page_content='Specialization'), Document(metadata={}, page_content='there.'), Document(metadata={}, page_content='He is 25 years old'), Document(metadata={}, page_content='currently and have'), Document(metadata={}, page_content='been working on'), Document(metadata={}, page_content='some personal'), Document(metadata={}, page_content='projects to extend'), Document(metadata={}, page_content='his expertise and'), Document(metadata={}, page_content='knowledge.'), Document(metadata={}, page_content='His personal hobby'), Document(metadata={}, page_content='is playing'), Document(metadata={}, page_content='basketball and'), Document(metadata={}, page_content='playing games.')]\n"
     ]
    }
   ],
   "source": [
    "print(\"#### Recursive Character Text Splitting ####\")\n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "with open('example_docs/content.txt', 'r', encoding='utf-8') as file:\n",
    "    text = file.read()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 20, chunk_overlap=0) # [\"\\n\\n\", \"\\n\", \" \", \"\"] 65,450\n",
    "print(text_splitter.create_documents([text])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4614262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reiner is a student | size = 19\n",
      "from National | size = 13\n",
      "University of | size = 13\n",
      "Singapore (NUS). He | size = 19\n",
      "is taking his | size = 13\n",
      "Master of Computing | size = 19\n",
      "with Artificial | size = 15\n",
      "Intelligence | size = 12\n",
      "Specialization | size = 14\n",
      "there. | size = 6\n",
      "He is 25 years old | size = 18\n",
      "currently and have | size = 18\n",
      "been working on | size = 15\n",
      "some personal | size = 13\n",
      "projects to extend | size = 18\n",
      "his expertise and | size = 17\n",
      "knowledge. | size = 10\n",
      "His personal hobby | size = 18\n",
      "is playing | size = 10\n",
      "basketball and | size = 14\n",
      "playing games. | size = 14\n"
     ]
    }
   ],
   "source": [
    "result = text_splitter.create_documents([text])\n",
    "# print(len(result))\n",
    "for i in result:\n",
    "    print(f'{i.page_content} | size = {len(i.page_content)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f52afc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Document Specific Splitting ####\n"
     ]
    }
   ],
   "source": [
    "# 3. Document Specific Splitting\n",
    "print(\"#### Document Specific Splitting ####\")\n",
    "\n",
    "# Document Specific Splitting - Markdown\n",
    "from langchain_text_splitters import MarkdownTextSplitter\n",
    "splitter = MarkdownTextSplitter(chunk_size = 40, chunk_overlap=0)\n",
    "markdown_text = \"\"\"\n",
    "# Fun in California\n",
    "\n",
    "## Driving\n",
    "\n",
    "Try driving on the 1 down to San Diego\n",
    "\n",
    "### Food\n",
    "\n",
    "Make sure to eat a burrito while you're there\n",
    "\n",
    "## Hiking\n",
    "\n",
    "Go to Yosemite\n",
    "\"\"\"\n",
    "result = splitter.create_documents([markdown_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11192c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Fun in California\n",
      "\n",
      "## Driving | size = 31\n",
      "Try driving on the 1 down to San Diego | size = 38\n",
      "### Food | size = 8\n",
      "Make sure to eat a burrito while you're | size = 39\n",
      "there | size = 5\n",
      "## Hiking\n",
      "\n",
      "Go to Yosemite | size = 25\n"
     ]
    }
   ],
   "source": [
    "# print(len(result))\n",
    "for i in result:\n",
    "    print(f'{i.page_content} | size = {len(i.page_content)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9367bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Document Specific Splitting - Python\n",
    "from langchain_text_splitters import PythonCodeTextSplitter\n",
    "python_text = \"\"\"\n",
    "class Person:\n",
    "  def __init__(self, name, age):\n",
    "    self.name = name\n",
    "    self.age = age\n",
    "\n",
    "p1 = Person(\"John\", 36)\n",
    "\n",
    "for i in range(10):\n",
    "    print (i)\n",
    "\"\"\"\n",
    "python_splitter = PythonCodeTextSplitter(chunk_size=100, chunk_overlap=0)\n",
    "result = python_splitter.create_documents([python_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6575cc82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class Person:\n",
      "  def __init__(self, name, age):\n",
      "    self.name = name\n",
      "    self.age = age ---> size = 86\n",
      "p1 = Person(\"John\", 36)\n",
      "\n",
      "for i in range(10):\n",
      "    print (i) ---> size = 58\n"
     ]
    }
   ],
   "source": [
    "# print(len(result))\n",
    "for i in result:\n",
    "    print(f'{i.page_content} ---> size = {len(i.page_content)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f84add5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q langchain-experimental"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74996fd5",
   "metadata": {},
   "source": [
    "### Semantic Chunking\n",
    "\n",
    "Semantic Chunking doesn't focus on the structure, it focuses on the meaning of the sections. It utilizes embedding and count the semantic similarity to split the text when the topic shifts.\n",
    "\n",
    "Advantage:\n",
    "+ Better precision, semantic chunking produces chunks that align closely with the user intent during retrieval.\n",
    "\n",
    "Drawbacks:\n",
    "- Computational Cost, this method is only suitable when accuracy is more important than speed. (example: domain-specific RAG system for legal or medical domains.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a791faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Semantic Chunking ####\n",
      "[Document(metadata={}, page_content='Reiner is a student from National University of Singapore (NUS). He is taking his Master of Computing with Artificial Intelligence Specialization there.'), Document(metadata={}, page_content='He is 25 years old currently and have been working on some personal projects to extend his expertise and knowledge. His personal hobby is playing basketball and playing games.')]\n"
     ]
    }
   ],
   "source": [
    "# 4. Semantic Chunking\n",
    "print(\"#### Semantic Chunking ####\")\n",
    "\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_ollama.embeddings import OllamaEmbeddings\n",
    "\n",
    "# Percentile - all differences between sentences are calculated, and then any difference greater than the X percentile is split\n",
    "text_splitter = SemanticChunker(OllamaEmbeddings(model=\"mxbai-embed-large\"))\n",
    "text_splitter = SemanticChunker(\n",
    "    OllamaEmbeddings(model=\"mxbai-embed-large\"), breakpoint_threshold_type=\"percentile\" # \"standard_deviation\", \"interquartile\"\n",
    ")\n",
    "documents = text_splitter.create_documents([text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "006f4119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reiner is a student from National University of Singapore (NUS). He is taking his Master of Computing with Artificial Intelligence Specialization there. ---> size = 152\n",
      "He is 25 years old currently and have been working on some personal projects to extend his expertise and knowledge. His personal hobby is playing basketball and playing games. ---> size = 175\n"
     ]
    }
   ],
   "source": [
    "# print(len(result))\n",
    "for i in documents:\n",
    "    print(f'{i.page_content} ---> size = {len(i.page_content)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dadba52",
   "metadata": {},
   "source": [
    "# Sliding Window Chunking\n",
    "\n",
    "This is the opposite of Semantic Chunking. Instead of keeping the semantic value, Sliding window aims to preserve the continuity of information which can increase the relevancy because multiple informations can be retrieved later. But the tradeoff here is that we are going to have redundancy of information. Having redundancy will increase the cost for storage and processing.\n",
    "\n",
    "This can be implemented by adjusting the chunk overlap value of the RecursiveCharacterTextSplitter. We should typically use 20–50% overlap between chunks to preserve context across boundaries, especially in technical or conversational text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a02e0297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Recursive Character Text Splitting ####\n",
      "[Document(metadata={}, page_content='Reiner is a student from National University of Singapore (NUS). He is taking his Master of'), Document(metadata={}, page_content='(NUS). He is taking his Master of Computing with Artificial Intelligence Specialization there.'), Document(metadata={}, page_content='He is 25 years old currently and have been working on some personal projects to extend his'), Document(metadata={}, page_content='personal projects to extend his expertise and knowledge.'), Document(metadata={}, page_content='His personal hobby is playing basketball and playing games.')]\n"
     ]
    }
   ],
   "source": [
    "print(\"#### Recursive Character Text Splitting ####\")\n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "with open('example_docs/content.txt', 'r', encoding='utf-8') as file:\n",
    "    text = file.read()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 100, chunk_overlap=35) # [\"\\n\\n\", \"\\n\", \" \", \"\"] 65,450\n",
    "print(text_splitter.create_documents([text])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f91bf3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reiner is a student from National University of Singapore (NUS). He is taking his Master of | size = 91\n",
      "(NUS). He is taking his Master of Computing with Artificial Intelligence Specialization there. | size = 94\n",
      "He is 25 years old currently and have been working on some personal projects to extend his | size = 90\n",
      "personal projects to extend his expertise and knowledge. | size = 56\n",
      "His personal hobby is playing basketball and playing games. | size = 59\n"
     ]
    }
   ],
   "source": [
    "result = text_splitter.create_documents([text])\n",
    "# print(len(result))\n",
    "for i in result:\n",
    "    print(f'{i.page_content} | size = {len(i.page_content)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7072e51",
   "metadata": {},
   "source": [
    "### Hierarchical and Contextual Chunking\n",
    "\n",
    "These chunking methods is used when continuity is not enough and the document structer has to be preserved.\n",
    "\n",
    "**Hierarchical Chunking** preserves the full structure of the document, from sections down to sentences. Instead of producing a flat list of chunks, it builds a tree that reflects the original hierarchy. Each chunk has a parent–child relationship with the levels above and below it. For example, a section contains multiple paragraphs (parent → children), and each paragraph may contain multiple sentences.\n",
    "\n",
    "During retrieval, this structure enables flexible navigation. If a query matches a sentence-level chunk, the system can expand upward to provide additional context from its parent paragraph or even the entire section. Conversely, if a broad query matches a section-level chunk, the system can drill down into the most relevant child paragraph or sentence. This multi-level retrieval improves both precision and recall, since the model can adapt the scope of the returned content.\n",
    "\n",
    "**Contextual chunking** goes a step further by enriching chunks with metadata such as headings, timestamps, or source references. This additional information provides important signals that help retrieval systems disambiguate results. For instance, two documents may contain nearly identical sentences, but their section titles or timestamps can determine which one is more relevant to a query. Metadata also makes it easier to trace answers back to their source, which is particularly valuable in regulated or compliance-driven domains.\n",
    "\n",
    "Advantage:\n",
    "+ both methods are accurate and flexible.\n",
    "\n",
    "Drawbacks:\n",
    "- Added complexity in both preprocessing and retrieval logic, since the system must manage relationships between chunks instead of treating them as independent units.\n",
    "\n",
    "These approaches might be suitable for domains like legal contracts, financial reports, or technical specifications, where preserving structure and traceability is essential."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d3f68d",
   "metadata": {},
   "source": [
    "### Topic-based and Modality-Specific Chunking\n",
    "\n",
    "These methods are the more flexible ways to group related content, because the structure or the hierarchy of all documents cannot be exactly identical.\n",
    "\n",
    "*Topic Based Chunking* groups text by thematic units using algorithms such as Latent Dirichlet Allocations (LDA) which is an embedding based clustering methods to identify semantic boundaries.\n",
    "\n",
    "Instead of fixed sizes or structural markers, the goal is to keep all content related to a theme in one place. This approach works well for long-form content such as research reports or articles that shift between distinct subjects. Because each chunk stays focused on a single theme, retrieval results are more aligned with user intent and less likely to include unrelated material.\n",
    "\n",
    "*Modality Specific Chunking* adapts strategies to different content types to ensure the information is segmented to respect the structure of the medium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d3a939",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
