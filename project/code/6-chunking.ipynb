{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fdfb478",
   "metadata": {},
   "source": [
    "# RAG from Scratch: Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "229abeba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q -U langchain langchain_core"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0d6825",
   "metadata": {},
   "source": [
    "## Chunking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0b1efc",
   "metadata": {},
   "source": [
    "Chunking is important to extract and group relevant informations in the same chunk so that when the retriever retrieve the data, the correct chunk will be pulled and it will bring the most relevant information.\n",
    "\n",
    "The chunk can be processed and embedded, and later the AI system can retrieve the embeddings to obtain the most relevant sources.\n",
    "\n",
    "Why Chunking is important?\n",
    "- LLM and RAG pipelines has limitation in the context windows and computational constraints, so we have to fit as much information as we can inside the same chunk.\n",
    "- Without proper chunking, we lose important contextual relationship and struggle to identify relevant information during retrieval.\n",
    "- Effective chunking will enhance the precision due to the semantically coherent segments that align with query patterns and user intent.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5687f7c2",
   "metadata": {},
   "source": [
    "\n",
    "## Common Chunking Strategies (w/ examples):\n",
    "\n",
    "> Example text:\n",
    ">\n",
    ">\"The Journey of a River from its source in the mountains through forests, cities, and finally into the sea is a fascinating story of nature's cycle and human interaction with the environment.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1a5acae",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"The Journey of a River from its source in the mountains through forests, cities, and finally into the sea is a fascinating story of nature's cycle and human interaction with the environment.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fc4c8b",
   "metadata": {},
   "source": [
    "### 1. Fixed Size Chunking\n",
    "This is the simplest but computationally effective method, it splits the text into chunk based on characters, words, or tokens without considering the meaning or the structure.\n",
    "\n",
    "Advantages:\n",
    "+ Fast\n",
    "+ Predictable\n",
    "+ Easy to implement\n",
    "\n",
    "Drawbacks:\n",
    "- Ignores semantic structure (reduces retrieval accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "596906a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Manual Character Text Splitting ####\n",
      "[Document(metadata={'source': 'local'}, page_content='The Journey of a River from its sou'), Document(metadata={'source': 'local'}, page_content='rce in the mountains through forest'), Document(metadata={'source': 'local'}, page_content='s, cities, and finally into the sea'), Document(metadata={'source': 'local'}, page_content=\" is a fascinating story of nature's\"), Document(metadata={'source': 'local'}, page_content=' cycle and human interaction with t'), Document(metadata={'source': 'local'}, page_content='he environment.')]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "print(\"#### Manual Character Text Splitting ####\")\n",
    "\n",
    "# manual character chunking\n",
    "chunks = []\n",
    "chunk_size = 35\n",
    "\n",
    "for i in range(0, len(text), chunk_size):\n",
    "    chunk = text[i:i + chunk_size]\n",
    "    chunks.append(chunk)\n",
    "    \n",
    "documents = [Document(page_content=chunk, metadata={\"source\": \"local\"}) for chunk in chunks]\n",
    "print(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef620aa",
   "metadata": {},
   "source": [
    "Result:\n",
    "\n",
    "[ <br/>\n",
    "    'The Journey of a River from its sou', <br/>\n",
    "    'rce in the mountains through forest', <br/>\n",
    "    's, cities, and finally into the sea', <br/>\n",
    "    \" is a fascinating story of nature's\", <br/>\n",
    "    ' cycle and human interaction with t', <br/>\n",
    "    'he environment.' <br/>\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c51b1f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Automatic Character Text Splitting ####\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/reiner/Documents/GitHub/llm_rag_from_scratch/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={}, page_content='The Journey of a River from its sou'), Document(metadata={}, page_content='s source in the mountains through f'), Document(metadata={}, page_content='ugh forests, cities, and finally in'), Document(metadata={}, page_content='ly into the sea is a fascinating st'), Document(metadata={}, page_content=\"ng story of nature's cycle and huma\"), Document(metadata={}, page_content=' human interaction with the environ'), Document(metadata={}, page_content='vironment.')]\n"
     ]
    }
   ],
   "source": [
    "# Automatic Text Splitting\n",
    "\n",
    "print(\"#### Automatic Character Text Splitting ####\")\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "text_splitter = CharacterTextSplitter(chunk_size = 35, chunk_overlap=5, separator='', strip_whitespace=False)\n",
    "documents = text_splitter.create_documents([text])\n",
    "print(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdc41fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Journey of a River from its sou | size = 35\n",
      "s source in the mountains through f | size = 35\n",
      "ugh forests, cities, and finally in | size = 35\n",
      "ly into the sea is a fascinating st | size = 35\n",
      "ng story of nature's cycle and huma | size = 35\n",
      " human interaction with the environ | size = 35\n",
      "vironment. | size = 10\n"
     ]
    }
   ],
   "source": [
    "# print(len(result))\n",
    "for i in documents:\n",
    "    print(f'{i.page_content} | size = {len(i.page_content)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86bd91f",
   "metadata": {},
   "source": [
    "The result is supposed to be exactly the same, but because we add overlap value of 5 characters, each Documents entry will overlap giving us even more result which could carry a more complete information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a725e2bb",
   "metadata": {},
   "source": [
    "### 2. Recursive Character Text Splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c7ac62",
   "metadata": {},
   "source": [
    "This is a more dynamic approach to the original chunking method and it focuses more on the structure. It will split the text based on the separator priority. By default, the separator priority is [\"\\n\\n\", \"\\n\", \" \", \"\"]. What is will do is split it one by one and check whether the size is still larger than the required chunk value, if true, it will chunk it into smaller sections with the next separator."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56601b2",
   "metadata": {},
   "source": [
    "sample text from `content.txt`:\n",
    "\n",
    "Reiner is a student from National University of Singapore (NUS). He is taking his Master of Computing with Artificial Intelligence Specialization there.\\n\\nHe is 25 years old currently and have been working on some personal projects to extend his expertise and knowledge.\\n\\nHis personal hobby is playing basketball and playing games."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59be5707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Recursive Character Text Splitting ####\n",
      "[Document(metadata={}, page_content='Reiner is a student'), Document(metadata={}, page_content='from National'), Document(metadata={}, page_content='University of'), Document(metadata={}, page_content='Singapore (NUS). He'), Document(metadata={}, page_content='is taking his'), Document(metadata={}, page_content='Master of Computing'), Document(metadata={}, page_content='with Artificial'), Document(metadata={}, page_content='Intelligence'), Document(metadata={}, page_content='Specialization'), Document(metadata={}, page_content='there.'), Document(metadata={}, page_content='He is 25 years old'), Document(metadata={}, page_content='currently and have'), Document(metadata={}, page_content='been working on'), Document(metadata={}, page_content='some personal'), Document(metadata={}, page_content='projects to extend'), Document(metadata={}, page_content='his expertise and'), Document(metadata={}, page_content='knowledge.'), Document(metadata={}, page_content='His personal hobby'), Document(metadata={}, page_content='is playing'), Document(metadata={}, page_content='basketball and'), Document(metadata={}, page_content='playing games.')]\n"
     ]
    }
   ],
   "source": [
    "print(\"#### Recursive Character Text Splitting ####\")\n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "with open('example_docs/content.txt', 'r', encoding='utf-8') as file:\n",
    "    text = file.read()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 20, chunk_overlap=0) # [\"\\n\\n\", \"\\n\", \" \", \"\"] 65,450\n",
    "print(text_splitter.create_documents([text])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4614262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reiner is a student | size = 19\n",
      "from National | size = 13\n",
      "University of | size = 13\n",
      "Singapore (NUS). He | size = 19\n",
      "is taking his | size = 13\n",
      "Master of Computing | size = 19\n",
      "with Artificial | size = 15\n",
      "Intelligence | size = 12\n",
      "Specialization | size = 14\n",
      "there. | size = 6\n",
      "He is 25 years old | size = 18\n",
      "currently and have | size = 18\n",
      "been working on | size = 15\n",
      "some personal | size = 13\n",
      "projects to extend | size = 18\n",
      "his expertise and | size = 17\n",
      "knowledge. | size = 10\n",
      "His personal hobby | size = 18\n",
      "is playing | size = 10\n",
      "basketball and | size = 14\n",
      "playing games. | size = 14\n"
     ]
    }
   ],
   "source": [
    "result = text_splitter.create_documents([text])\n",
    "# print(len(result))\n",
    "for i in result:\n",
    "    print(f'{i.page_content} | size = {len(i.page_content)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f52afc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Document Specific Splitting ####\n"
     ]
    }
   ],
   "source": [
    "# 3. Document Specific Splitting\n",
    "print(\"#### Document Specific Splitting ####\")\n",
    "\n",
    "# Document Specific Splitting - Markdown\n",
    "from langchain_text_splitters import MarkdownTextSplitter\n",
    "splitter = MarkdownTextSplitter(chunk_size = 40, chunk_overlap=0)\n",
    "markdown_text = \"\"\"\n",
    "# Fun in California\n",
    "\n",
    "## Driving\n",
    "\n",
    "Try driving on the 1 down to San Diego\n",
    "\n",
    "### Food\n",
    "\n",
    "Make sure to eat a burrito while you're there\n",
    "\n",
    "## Hiking\n",
    "\n",
    "Go to Yosemite\n",
    "\"\"\"\n",
    "result = splitter.create_documents([markdown_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11192c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Fun in California\n",
      "\n",
      "## Driving | size = 31\n",
      "Try driving on the 1 down to San Diego | size = 38\n",
      "### Food | size = 8\n",
      "Make sure to eat a burrito while you're | size = 39\n",
      "there | size = 5\n",
      "## Hiking\n",
      "\n",
      "Go to Yosemite | size = 25\n"
     ]
    }
   ],
   "source": [
    "# print(len(result))\n",
    "for i in result:\n",
    "    print(f'{i.page_content} | size = {len(i.page_content)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9367bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Document Specific Splitting - Python\n",
    "from langchain_text_splitters import PythonCodeTextSplitter\n",
    "python_text = \"\"\"\n",
    "class Person:\n",
    "  def __init__(self, name, age):\n",
    "    self.name = name\n",
    "    self.age = age\n",
    "\n",
    "p1 = Person(\"John\", 36)\n",
    "\n",
    "for i in range(10):\n",
    "    print (i)\n",
    "\"\"\"\n",
    "python_splitter = PythonCodeTextSplitter(chunk_size=100, chunk_overlap=0)\n",
    "result = python_splitter.create_documents([python_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6575cc82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class Person:\n",
      "  def __init__(self, name, age):\n",
      "    self.name = name\n",
      "    self.age = age ---> size = 86\n",
      "p1 = Person(\"John\", 36)\n",
      "\n",
      "for i in range(10):\n",
      "    print (i) ---> size = 58\n"
     ]
    }
   ],
   "source": [
    "# print(len(result))\n",
    "for i in result:\n",
    "    print(f'{i.page_content} ---> size = {len(i.page_content)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f84add5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q langchain-experimental"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74996fd5",
   "metadata": {},
   "source": [
    "### Semantic Chunking\n",
    "\n",
    "Semantic Chunking doesn't focus on the structure, it focuses on the meaning of the sections. It utilizes embedding and count the semantic similarity to split the text when the topic shifts.\n",
    "\n",
    "Advantage:\n",
    "+ Better precision, semantic chunking produces chunks that align closely with the user intent during retrieval.\n",
    "\n",
    "Drawbacks:\n",
    "- Computational Cost, this method is only suitable when accuracy is more important than speed. (example: domain-specific RAG system for legal or medical domains.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a791faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Semantic Chunking ####\n"
     ]
    }
   ],
   "source": [
    "# 4. Semantic Chunking\n",
    "print(\"#### Semantic Chunking ####\")\n",
    "\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_ollama.embeddings import OllamaEmbeddings\n",
    "\n",
    "# Percentile - all differences between sentences are calculated, and then any difference greater than the X percentile is split\n",
    "text_splitter = SemanticChunker(OllamaEmbeddings(model=\"mxbai-embed-large\"))\n",
    "text_splitter = SemanticChunker(\n",
    "    OllamaEmbeddings(model=\"mxbai-embed-large\"), breakpoint_threshold_type=\"percentile\" # \"standard_deviation\", \"interquartile\"\n",
    ")\n",
    "documents = text_splitter.create_documents([text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "006f4119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reiner is a student from National University of Singapore (NUS). He is taking his Master of Computing with Artificial Intelligence Specialization there. ---> size = 152\n",
      "He is 25 years old currently and have been working on some personal projects to extend his expertise and knowledge. His personal hobby is playing basketball and playing games. ---> size = 175\n"
     ]
    }
   ],
   "source": [
    "# print(len(result))\n",
    "for i in documents:\n",
    "    print(f'{i.page_content} ---> size = {len(i.page_content)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dadba52",
   "metadata": {},
   "source": [
    "# Sliding Window Chunking\n",
    "\n",
    "This is the opposite of Semantic Chunking. Instead of keeping the semantic value, Sliding window aims to preserve the continuity of information which can increase the relevancy because multiple informations can be retrieved later. But the tradeoff here is that we are going to have redundancy of information. Having redundancy will increase the cost for storage and processing.\n",
    "\n",
    "This can be implemented by adjusting the chunk overlap value of the RecursiveCharacterTextSplitter. We should typically use 20–50% overlap between chunks to preserve context across boundaries, especially in technical or conversational text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a02e0297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Recursive Character Text Splitting ####\n",
      "[Document(metadata={}, page_content='Reiner is a student from National University of Singapore (NUS). He is taking his Master of'), Document(metadata={}, page_content='(NUS). He is taking his Master of Computing with Artificial Intelligence Specialization there.'), Document(metadata={}, page_content='He is 25 years old currently and have been working on some personal projects to extend his'), Document(metadata={}, page_content='personal projects to extend his expertise and knowledge.'), Document(metadata={}, page_content='His personal hobby is playing basketball and playing games.')]\n"
     ]
    }
   ],
   "source": [
    "print(\"#### Recursive Character Text Splitting ####\")\n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "with open('example_docs/content.txt', 'r', encoding='utf-8') as file:\n",
    "    text = file.read()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 100, chunk_overlap=35) # [\"\\n\\n\", \"\\n\", \" \", \"\"] 65,450\n",
    "print(text_splitter.create_documents([text])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f91bf3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reiner is a student from National University of Singapore (NUS). He is taking his Master of | size = 91\n",
      "(NUS). He is taking his Master of Computing with Artificial Intelligence Specialization there. | size = 94\n",
      "He is 25 years old currently and have been working on some personal projects to extend his | size = 90\n",
      "personal projects to extend his expertise and knowledge. | size = 56\n",
      "His personal hobby is playing basketball and playing games. | size = 59\n"
     ]
    }
   ],
   "source": [
    "result = text_splitter.create_documents([text])\n",
    "# print(len(result))\n",
    "for i in result:\n",
    "    print(f'{i.page_content} | size = {len(i.page_content)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7072e51",
   "metadata": {},
   "source": [
    "### Hierarchical and Contextual Chunking\n",
    "\n",
    "These chunking methods is used when continuity is not enough and the document structer has to be preserved.\n",
    "\n",
    "**Hierarchical Chunking** preserves the full structure of the document, from sections down to sentences. Instead of producing a flat list of chunks, it builds a tree that reflects the original hierarchy. Each chunk has a parent–child relationship with the levels above and below it. For example, a section contains multiple paragraphs (parent → children), and each paragraph may contain multiple sentences.\n",
    "\n",
    "During retrieval, this structure enables flexible navigation. If a query matches a sentence-level chunk, the system can expand upward to provide additional context from its parent paragraph or even the entire section. Conversely, if a broad query matches a section-level chunk, the system can drill down into the most relevant child paragraph or sentence. This multi-level retrieval improves both precision and recall, since the model can adapt the scope of the returned content.\n",
    "\n",
    "**Contextual chunking** goes a step further by enriching chunks with metadata such as headings, timestamps, or source references. This additional information provides important signals that help retrieval systems disambiguate results. For instance, two documents may contain nearly identical sentences, but their section titles or timestamps can determine which one is more relevant to a query. Metadata also makes it easier to trace answers back to their source, which is particularly valuable in regulated or compliance-driven domains.\n",
    "\n",
    "Advantage:\n",
    "+ both methods are accurate and flexible.\n",
    "\n",
    "Drawbacks:\n",
    "- Added complexity in both preprocessing and retrieval logic, since the system must manage relationships between chunks instead of treating them as independent units.\n",
    "\n",
    "These approaches might be suitable for domains like legal contracts, financial reports, or technical specifications, where preserving structure and traceability is essential."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d3f68d",
   "metadata": {},
   "source": [
    "### Topic-based and Modality-Specific Chunking\n",
    "\n",
    "These methods are the more flexible ways to group related content, because the structure or the hierarchy of all documents cannot be exactly identical.\n",
    "\n",
    "*Topic Based Chunking* groups text by thematic units using algorithms such as Latent Dirichlet Allocations (LDA) which is an embedding based clustering methods to identify semantic boundaries.\n",
    "\n",
    "Instead of fixed sizes or structural markers, the goal is to keep all content related to a theme in one place. This approach works well for long-form content such as research reports or articles that shift between distinct subjects. Because each chunk stays focused on a single theme, retrieval results are more aligned with user intent and less likely to include unrelated material.\n",
    "\n",
    "*Modality Specific Chunking* adapts strategies to different content types to ensure the information is segmented to respect the structure of the medium."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e5f605",
   "metadata": {},
   "source": [
    "### Agentic Chunker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "51d3a939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Proposition-Based Chunking ####\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'create_extraction_chain_pydantic' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[32m     23\u001b[39m     sentences: List[\u001b[38;5;28mstr\u001b[39m]\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# Extraction\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m extraction_chain = \u001b[43mcreate_extraction_chain_pydantic\u001b[49m(pydantic_schema=Sentences, llm=llm)\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_propositions\u001b[39m(text):\n\u001b[32m     28\u001b[39m     runnable_output = runnable.invoke({\n\u001b[32m     29\u001b[39m     \t\u001b[33m\"\u001b[39m\u001b[33minput\u001b[39m\u001b[33m\"\u001b[39m: text\n\u001b[32m     30\u001b[39m     }).content\n",
      "\u001b[31mNameError\u001b[39m: name 'create_extraction_chain_pydantic' is not defined"
     ]
    }
   ],
   "source": [
    "# 5. Agentic Chunking\n",
    "print(\"#### Proposition-Based Chunking ####\")\n",
    "\n",
    "# https://arxiv.org/pdf/2312.06648.pdf\n",
    "\n",
    "# from langchain.output_parsers.openai_tools import JsonOutputToolsParser\n",
    "# from langchain_openai import ChatOpenAI\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "# from langchain.chains import create_extraction_chain\n",
    "from typing import Optional, List\n",
    "# from langchain.chains import create_extraction_chain_pydantic\n",
    "from pydantic import BaseModel\n",
    "from langchain_classic import hub\n",
    "\n",
    "obj = hub.pull(\"wfh/proposal-indexing\")\n",
    "llm = ChatOllama(model='llama3.1')\n",
    "llm\n",
    "runnable = obj | llm\n",
    "\n",
    "class Sentences(BaseModel):\n",
    "    sentences: List[str]\n",
    "    \n",
    "# Extraction\n",
    "extraction_chain = create_extraction_chain_pydantic(pydantic_schema=Sentences, llm=llm)\n",
    "def get_propositions(text):\n",
    "    runnable_output = runnable.invoke({\n",
    "    \t\"input\": text\n",
    "    }).content\n",
    "    propositions = extraction_chain.invoke(runnable_output)[\"text\"][0].sentences\n",
    "    return propositions\n",
    "    \n",
    "paragraphs = text.split(\"\\n\\n\")\n",
    "text_propositions = []\n",
    "for i, para in enumerate(paragraphs[:5]):\n",
    "    propositions = get_propositions(para)\n",
    "    text_propositions.extend(propositions)\n",
    "    print (f\"Done with {i}\")\n",
    "\n",
    "print (f\"You have {len(text_propositions)} propositions\")\n",
    "print(text_propositions[:10])\n",
    "\n",
    "print(\"#### Agentic Chunking ####\")\n",
    "\n",
    "from utils.agentic_chunker import AgenticChunker\n",
    "ac = AgenticChunker()\n",
    "ac.add_propositions(text_propositions)\n",
    "print(ac.pretty_print_chunks())\n",
    "chunks = ac.get_chunks(get_type='list_of_strings')\n",
    "print(chunks)\n",
    "documents = [Document(page_content=chunk, metadata={\"source\": \"local\"}) for chunk in chunks]\n",
    "rag(documents, \"agentic-chunks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2ab1b5",
   "metadata": {},
   "source": [
    "The Agentic chunker still have some issues with the library, but this is the sample result of every chunker:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ea6817",
   "metadata": {},
   "source": [
    "#### Character Text Splitting ####\n",
    "[\n",
    "    Document(page_content='Text splitting in LangChain is a cr', metadata={'source': 'local'}),\n",
    "    Document(page_content='itical feature that facilitates the', metadata={'source': 'local'}),\n",
    "    Document(page_content=' division of large texts into small', metadata={'source': 'local'}),\n",
    "    Document(page_content='er, manageable segments. ', metadata={'source': 'local'})\n",
    "]\n",
    "[\n",
    "    Document(page_content='Text splitting in LangChain is a cr'),\n",
    "    Document(page_content='itical feature that facilitates the'),\n",
    "    Document(page_content=' division of large texts into small'),\n",
    "    Document(page_content='er, manageable segments. ')\n",
    "]\n",
    "#### Recursive Character Text Splitting ####\n",
    "[\n",
    "    Document(page_content='Text splitting in LangChain is a critical feature that'),\n",
    "    Document(page_content='facilitates the division of large texts into smaller, manageable'),\n",
    "    Document(page_content='segments.'),\n",
    "    Document(page_content='This capability is vital for improving comprehension and'),\n",
    "    Document(page_content='processing efficiency, especially in tasks that require detailed'),\n",
    "    Document(page_content='analysis or extraction of specific contexts.'),\n",
    "    Document(page_content='ChatGPT, developed by OpenAI, represents a leap forward in'),\n",
    "    Document(page_content='natural language processing technologies.'),\n",
    "    Document(page_content=\"It's a conversational AI model capable of understanding and\"),\n",
    "    Document(page_content='generating human-like text, allowing for dynamic interactions'),\n",
    "    Document(page_content='and providing responses that are remarkably coherent and'),\n",
    "    Document(page_content='contextually relevant. ChatGPT has been integrated into a'),\n",
    "    Document(page_content='multitude of applications, revolutionizing the way we interact'),\n",
    "    Document(page_content='with machines and access information.'),\n",
    "    Document(page_content='By leveraging LangChain for text splitting, users can'),\n",
    "    Document(page_content='efficiently navigate and analyze vast amounts of text data,'),\n",
    "    Document(page_content='facilitating a deeper understanding and more insightful'),\n",
    "    Document(page_content='conclusions.')\n",
    "]\n",
    "#### Document Specific Splitting ####\n",
    "[\n",
    "    Document(page_content='# Fun in California\\n\\n## Driving'),\n",
    "    Document(page_content='Try driving on the 1 down to San Diego'),\n",
    "    Document(page_content='### Food'),\n",
    "    Document(page_content=\"Make sure to eat a burrito while you're\"),\n",
    "    Document(page_content='there'),\n",
    "    Document(page_content='## Hiking\\n\\nGo to Yosemite')\n",
    "]\n",
    "[\n",
    "    Document(page_content='class Person:\\n  def __init__(self, name, age):\\n    self.name = name\\n    self.age = age'),\n",
    "    Document(page_content='p1 = Person(\"John\", 36)\\n\\nfor i in range(10):\\n    print (i)')\n",
    "]\n",
    "[\n",
    "    Document(page_content='// Function is called, the return value will end up in x'),\n",
    "    Document(page_content='let x = myFunction(4, 3);'),\n",
    "    Document(page_content='function myFunction(a, b) {'),\n",
    "    Document(page_content='// Function returns the product of a and b\\n  return a * b;\\n}')\n",
    "]\n",
    "#### Semantic Chunking ####\n",
    "[\n",
    "    Document(\n",
    "        page_content='Text splitting in LangChain is a critical feature that facilitates the division of large texts into \n",
    "smaller, manageable segments. This capability is vital for improving comprehension and processing efficiency, especially in tasks\n",
    "that require detailed analysis or extraction of specific contexts.'\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"ChatGPT, developed by OpenAI, represents a leap forward in natural language processing technologies. It's a\n",
    "conversational AI model capable of understanding and generating human-like text, allowing for dynamic interactions and providing \n",
    "responses that are remarkably coherent and contextually relevant. ChatGPT has been integrated into a multitude of applications, \n",
    "revolutionizing the way we interact with machines and access information. By leveraging LangChain for text splitting, users can \n",
    "efficiently navigate and analyze vast amounts of text data, facilitating a deeper understanding and more insightful conclusions.\"\n",
    "    )\n",
    "]\n",
    "#### Proposition-Based Chunking ####\n",
    "Done with 0\n",
    "Done with 1\n",
    "Done with 2\n",
    "You have 17 propositions\n",
    "[\n",
    "    'Text splitting in LangChain is a critical feature.',\n",
    "    'Text splitting facilitates the division of large texts into smaller, manageable segments.',\n",
    "    'This capability is vital for improving comprehension and processing efficiency.',\n",
    "    'It is especially important in tasks that require detailed analysis or extraction of specific contexts.',\n",
    "    'ChatGPT was developed by OpenAI.',\n",
    "    'OpenAI developed ChatGPT.',\n",
    "    'ChatGPT represents a leap forward in natural language processing technologies.',\n",
    "    'ChatGPT is a conversational AI model.',\n",
    "    'ChatGPT is capable of understanding and generating human-like text.',\n",
    "    'ChatGPT allows for dynamic interactions.'\n",
    "]\n",
    "#### Agentic Chunking ####\n",
    "\n",
    "Adding: 'Text splitting in LangChain is a critical feature.'\n",
    "No chunks, creating a new one\n",
    "Created new chunk (0e05f): LangChain Features\n",
    "\n",
    "Adding: 'Text splitting facilitates the division of large texts into smaller, manageable segments.'\n",
    "No chunks found\n",
    "Created new chunk (471d6): Text Segmentation Techniques\n",
    "\n",
    "Adding: 'This capability is vital for improving comprehension and processing efficiency.'\n",
    "No chunks found\n",
    "Created new chunk (9ba91): Capabilities Importance & Benefits\n",
    "\n",
    "Adding: 'It is especially important in tasks that require detailed analysis or extraction of specific contexts.'\n",
    "No chunks found\n",
    "Created new chunk (3af8b): Analytical Processes\n",
    "\n",
    "Adding: 'ChatGPT was developed by OpenAI.'\n",
    "No chunks found\n",
    "Created new chunk (e2947): ChatGPT Development & Features\n",
    "\n",
    "Adding: 'OpenAI developed ChatGPT.'\n",
    "Chunk Found (e2947), adding to: ChatGPT Development & Features\n",
    "\n",
    "Adding: 'ChatGPT represents a leap forward in natural language processing technologies.'\n",
    "Chunk Found (e2947), adding to: ChatGPT Development\n",
    "\n",
    "Adding: 'ChatGPT is a conversational AI model.'\n",
    "Chunk Found (e2947), adding to: Advancements in Natural Language Processing\n",
    "\n",
    "Adding: 'ChatGPT is capable of understanding and generating human-like text.'\n",
    "Chunk Found (e2947), adding to: ChatGPT: Development and Capabilities\n",
    "\n",
    "Adding: 'ChatGPT allows for dynamic interactions.'\n",
    "Chunk Found (e2947), adding to: ChatGPT: Development, Capabilities, and Significance\n",
    "\n",
    "Adding: 'ChatGPT provides responses that are remarkably coherent and contextually relevant.'\n",
    "Chunk Found (e2947), adding to: ChatGPT: Overview and Innovations\n",
    "\n",
    "Adding: 'ChatGPT has been integrated into a multitude of applications.'\n",
    "Chunk Found (e2947), adding to: ChatGPT: Development, Capabilities & Impact\n",
    "\n",
    "Adding: 'ChatGPT revolutionized the way we interact with machines.'\n",
    "Chunk Found (e2947), adding to: ChatGPT: Overview & Applications\n",
    "\n",
    "Adding: 'ChatGPT revolutionized the way we access information.'\n",
    "Chunk Found (e2947), adding to: ChatGPT: Development, Capabilities & Impact\n",
    "\n",
    "Adding: 'Users can leverage LangChain for text splitting.'\n",
    "Chunk Found (0e05f), adding to: LangChain Features\n",
    "\n",
    "Adding: 'LangChain allows users to efficiently navigate and analyze vast amounts of text data.'\n",
    "Chunk Found (0e05f), adding to: Using LangChain for Text Splitting\n",
    "\n",
    "Adding: 'Text splitting with LangChain facilitates a deeper understanding and more insightful conclusions.'\n",
    "Chunk Found (0e05f), adding to: LangChain Text Splitting and Analysis\n",
    "\n",
    "You have 5 chunks\n",
    "\n",
    "Chunk #0\n",
    "Chunk ID: 0e05f\n",
    "Summary: This chunk contains information about using LangChain for text splitting, including its advantages for navigating, \n",
    "analyzing, and understanding large text datasets.\n",
    "Propositions:\n",
    "    -Text splitting in LangChain is a critical feature.\n",
    "    -Users can leverage LangChain for text splitting.\n",
    "    -LangChain allows users to efficiently navigate and analyze vast amounts of text data.\n",
    "    -Text splitting with LangChain facilitates a deeper understanding and more insightful conclusions.\n",
    "\n",
    "\n",
    "\n",
    "Chunk #1\n",
    "Chunk ID: 471d6\n",
    "Summary: This chunk contains information about techniques and methods for dividing texts into smaller segments.\n",
    "Propositions:\n",
    "    -Text splitting facilitates the division of large texts into smaller, manageable segments.\n",
    "\n",
    "\n",
    "\n",
    "Chunk #2\n",
    "Chunk ID: 9ba91\n",
    "Summary: This chunk contains information about the importance and benefits of certain capabilities.\n",
    "Propositions:\n",
    "    -This capability is vital for improving comprehension and processing efficiency.\n",
    "\n",
    "\n",
    "\n",
    "Chunk #3\n",
    "Chunk ID: 3af8b\n",
    "Summary: This chunk contains information about the importance of certain processes in tasks requiring detailed analysis or \n",
    "context extraction.\n",
    "Propositions:\n",
    "    -It is especially important in tasks that require detailed analysis or extraction of specific contexts.\n",
    "\n",
    "\n",
    "\n",
    "Chunk #4\n",
    "Chunk ID: e2947\n",
    "Summary: This chunk contains information about the development, capabilities, significance, functionalities, and applications of \n",
    "ChatGPT, a conversational AI model by OpenAI.\n",
    "Propositions:\n",
    "    -ChatGPT was developed by OpenAI.\n",
    "    -OpenAI developed ChatGPT.\n",
    "    -ChatGPT represents a leap forward in natural language processing technologies.\n",
    "    -ChatGPT is a conversational AI model.\n",
    "    -ChatGPT is capable of understanding and generating human-like text.\n",
    "    -ChatGPT allows for dynamic interactions.\n",
    "    -ChatGPT provides responses that are remarkably coherent and contextually relevant.\n",
    "    -ChatGPT has been integrated into a multitude of applications.\n",
    "    -ChatGPT revolutionized the way we interact with machines.\n",
    "    -ChatGPT revolutionized the way we access information.\n",
    "\n",
    "\n",
    "\n",
    "None\n",
    "[\n",
    "    'Text splitting in LangChain is a critical feature. Users can leverage LangChain for text splitting. LangChain allows users \n",
    "to efficiently navigate and analyze vast amounts of text data. Text splitting with LangChain facilitates a deeper understanding \n",
    "and more insightful conclusions.',\n",
    "    'Text splitting facilitates the division of large texts into smaller, manageable segments.',\n",
    "    'This capability is vital for improving comprehension and processing efficiency.',\n",
    "    'It is especially important in tasks that require detailed analysis or extraction of specific contexts.',\n",
    "    'ChatGPT was developed by OpenAI. OpenAI developed ChatGPT. ChatGPT represents a leap forward in natural language processing \n",
    "technologies. ChatGPT is a conversational AI model. ChatGPT is capable of understanding and generating human-like text. ChatGPT \n",
    "allows for dynamic interactions. ChatGPT provides responses that are remarkably coherent and contextually relevant. ChatGPT has \n",
    "been integrated into a multitude of applications. ChatGPT revolutionized the way we interact with machines. ChatGPT \n",
    "revolutionized the way we access information.'\n",
    "]\n",
    " Text splitting is a feature used to divide large texts into smaller, manageable segments. This facilitates improved \n",
    "comprehension and processing efficiency, making it especially important in tasks that require detailed analysis or extraction of \n",
    "specific contexts. It enables users to more efficiently navigate and analyze vast amounts of text data, leading to deeper \n",
    "understanding and more insightful conclusions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
